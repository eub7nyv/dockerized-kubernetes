#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

version: "3.7"

x-bakctl: &build-args-kubectl-k8
  KUBECTL_TAG: ${K8_VERSION}
  K8_VERSION: ${K8_VERSION}
x-baetcd: &build-args-etcd
  ETCD_VERSION: ${ETCD_VERSION}
x-bakubelet: &build-args-kubelet
  CRICTL_VERSION: ${CRICTL_VERSION}
  RUNC_VERSION: ${RUNC_VERSION}
  CNI_VERSION: ${CNI_VERSION}
  CONTAINERD_VERSION: ${CONTAINERD_VERSION}
x-da: &depends-on-apiserver
  depends_on: ["kubectl", "etcd", "kube-apiserver"]
  restart: always
x-dofk: &depends-on-for-kubelet
  depends_on:
    [
      "kubectl",
      "etcd",
      "kube-apiserver",
      "kube-controller-manager",
      "kube-scheduler",
    ]
  restart: always
x-lr: &do-leave-running
  stdin_open: true
  tty: true
  restart: always
x-env: &ip-env
  environment:
    - K8_NET_IP_RANGE=${K8_NET_IP_RANGE}
    - K8_NET_IP_RANGE_BASE=${K8_NET_IP_RANGE_BASE}
    - K8_NET_IP_RANGE_MASK=${K8_NET_IP_RANGE_MASK}
    - K8_NET_SVC_IP_RANGE=${K8_NET_SVC_IP_RANGE}
    - K8_NET_SVC_IP_RANGE_BASE=${K8_NET_SVC_IP_RANGE_BASE}
    - K8_NET_SVC_IP_RANGE_MASK=${K8_NET_SVC_IP_RANGE_MASK}
    - KUBECTL_IP=${KUBECTL_IP}
    - K8_ETCD_IP=${K8_ETCD_IP}
    - KUBE_APISERVER_IP=${KUBE_APISERVER_IP}
    - KUBE_CONTROLLER_MANAGER_IP=${KUBE_CONTROLLER_MANAGER_IP}
    - KUBE_SCHEDULER_IP=${KUBE_SCHEDULER_IP}
    - KUBELET_BASE_IP=${KUBELET_BASE_IP}
    - KUBELET_0_IP=${KUBELET_0_IP}
    - KUBELET_1_IP=${KUBELET_1_IP}
    - KUBELET_2_IP=${KUBELET_2_IP}

services:
  # Base image that the rest of this depends on
  kubectl:
    build:
      context: ./kubectl
      args:
        K8_VERSION: ${K8_VERSION}
        CFSSL_VERSION: ${CFSSL_VERSION}
        K8_NET_IP_RANGE_BASE: ${K8_NET_IP_RANGE_BASE}
        K8_NET_IP_RANGE_MASK: ${K8_NET_IP_RANGE_MASK}
        K8_NET_SVC_IP_RANGE_BASE: ${K8_NET_SVC_IP_RANGE_BASE}
        K8_NET_SVC_IP_RANGE_MASK: ${K8_NET_SVC_IP_RANGE_MASK}
        KUBECTL_IP: ${KUBECTL_IP}
        K8_ETCD_IP: ${K8_ETCD_IP}
        KUBE_APISERVER_IP: ${KUBE_APISERVER_IP}
        KUBE_CONTROLLER_MANAGER_IP: ${KUBE_CONTROLLER_MANAGER_IP}
        KUBE_SCHEDULER_IP: ${KUBE_SCHEDULER_IP}
        KUBELET_BASE_IP: ${KUBELET_BASE_IP}
        KUBELET_0_IP: ${KUBELET_0_IP}
        KUBELET_1_IP: ${KUBELET_1_IP}
        KUBELET_2_IP: ${KUBELET_2_IP}
    image: "kubectl:${K8_VERSION}"
    <<: *do-leave-running
    <<: *ip-env
    networks:
      k8:
        ipv4_address: ${KUBECTL_IP}
  # Build out etcd from the kubectl
  etcd:
    build:
      context: ./etcd
      args:
        <<: *build-args-kubectl-k8
        <<: *build-args-etcd
    image: "k8-etcd:${ETCD_VERSION}"
    <<: *ip-env
    depends_on: ["kubectl"]
    restart: always
    ports:
      - 2379:2379
      - 2380:2380
    networks:
      k8:
        ipv4_address: ${K8_ETCD_IP}
  # Typically this (api-server) and the controller-manager/scheduler are deployed together, but...
  # DOCKER!
  kube-apiserver:
    build:
      context: ./kube-apiserver
      args:
        <<: *build-args-kubectl-k8
    image: "k8-apiserver:${K8_VERSION}"
    <<: *ip-env
    depends_on: ["kubectl", "etcd"]
    restart: always
    ports:
      - 8080:8080
      - 6443:6443
    networks:
      k8:
        ipv4_address: ${KUBE_APISERVER_IP}
  # Typically this (controller-manager) and the scheduler/api-server are deployed together, but...
  # DOCKER!
  kube-controller-manager:
    build:
      context: ./kube-controller-manager
      args:
        <<: *build-args-kubectl-k8
    image: "k8-controller-manager:${K8_VERSION}"
    <<: *ip-env
    <<: *depends-on-apiserver
    ports:
      - 10252:10252
      - 10257:10257
    networks:
      k8:
        ipv4_address: ${KUBE_CONTROLLER_MANAGER_IP}
  # Typically this (scheduler) and the controller-manager/api-server are deployed together, but...
  # DOCKER!
  kube-scheduler:
    build:
      context: ./kube-scheduler
      args:
        <<: *build-args-kubectl-k8
    image: "k8-scheduler:${K8_VERSION}"
    <<: *ip-env
    <<: *depends-on-apiserver
    ports:
      - 10251:10251
      - 10259:10259
    networks:
      k8:
        ipv4_address: ${KUBE_SCHEDULER_IP}
  # We want three nodes... 1/3
  kubelet_0:
    build:
      context: ./kubelet
      args:
        <<: *build-args-kubectl-k8
        <<: *build-args-kubelet
    image: k8-kubelet:${K8_VERSION}
    <<: *ip-env
    <<: *depends-on-for-kubelet
    ports:
      - 10250:10250
      - 10255:10255
    networks:
      k8:
        ipv4_address: ${KUBELET_0_IP}
  # We want three nodes... 2/3
  kubelet_1:
    image: k8-kubelet:${K8_VERSION}
    <<: *ip-env
    <<: *depends-on-for-kubelet
    networks:
      k8:
        ipv4_address: ${KUBELET_1_IP}
  # We want three nodes... 3/3
  kubelet_2:
    image: k8-kubelet:${K8_VERSION}
    <<: *ip-env
    <<: *depends-on-for-kubelet
    networks:
      k8:
        ipv4_address: ${KUBELET_2_IP}

networks:
  k8:
    ipam:
      driver: default
      config:
        - subnet: "${K8_NET_IP_RANGE_BASE}/${K8_NET_IP_RANGE_MASK}"
